{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOboR2iAKPMdufGvL626K2E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0005fbf2a87847199378408b09212f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74aca8dabce041e8a0583200aaff3686",
              "IPY_MODEL_c50e5f28bf4748a1ab4a2746b2f0acc6",
              "IPY_MODEL_92098aa911fa41fca3f774a7de67c5ac"
            ],
            "layout": "IPY_MODEL_b2434f60b020459d8095e044ea2b71de"
          }
        },
        "74aca8dabce041e8a0583200aaff3686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7c78436f784cabb6756e5090348601",
            "placeholder": "​",
            "style": "IPY_MODEL_2527478b8dca481c99b2af8ab068687e",
            "value": "Map: 100%"
          }
        },
        "c50e5f28bf4748a1ab4a2746b2f0acc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_908cc113e54c46a8bc2afa33131d72c9",
            "max": 5531,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_46521500ad6240e8bd1930be4174161a",
            "value": 5531
          }
        },
        "92098aa911fa41fca3f774a7de67c5ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79da89d71faf40909100f25e39189755",
            "placeholder": "​",
            "style": "IPY_MODEL_0f82fdbd01d94d7491c4dfa9eef2fed9",
            "value": " 5531/5531 [00:05&lt;00:00, 1159.73 examples/s]"
          }
        },
        "b2434f60b020459d8095e044ea2b71de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7c78436f784cabb6756e5090348601": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2527478b8dca481c99b2af8ab068687e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "908cc113e54c46a8bc2afa33131d72c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46521500ad6240e8bd1930be4174161a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79da89d71faf40909100f25e39189755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f82fdbd01d94d7491c4dfa9eef2fed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a30ea0ddc6bc48bbae6409a5addef14c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6f7a2d12c114413901d6ddac26ff2be",
              "IPY_MODEL_527162e9b6ee439ca430c5ea67c5515a",
              "IPY_MODEL_9213f10e98004c358d82593202e1321f"
            ],
            "layout": "IPY_MODEL_afd147215d8b44eba95138a12189b064"
          }
        },
        "d6f7a2d12c114413901d6ddac26ff2be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070a91728647468a82402f64e8ba3a44",
            "placeholder": "​",
            "style": "IPY_MODEL_12aa1ada85de4aa68943d074f7c828a5",
            "value": "Map: 100%"
          }
        },
        "527162e9b6ee439ca430c5ea67c5515a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f7347b44f4443086bc9e0a9c1e68a3",
            "max": 724,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13f90c06d3b84a5baebf9ebbcede294f",
            "value": 724
          }
        },
        "9213f10e98004c358d82593202e1321f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a9c9ad56f942e4b001f085bd9b7184",
            "placeholder": "​",
            "style": "IPY_MODEL_73901dd33aab4fdfb00683b2f16e68a8",
            "value": " 724/724 [00:00&lt;00:00, 1245.93 examples/s]"
          }
        },
        "afd147215d8b44eba95138a12189b064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070a91728647468a82402f64e8ba3a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12aa1ada85de4aa68943d074f7c828a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12f7347b44f4443086bc9e0a9c1e68a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13f90c06d3b84a5baebf9ebbcede294f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58a9c9ad56f942e4b001f085bd9b7184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73901dd33aab4fdfb00683b2f16e68a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/r-m-steffi/Bart_EAMT/blob/main/Bart_semeval_EAMT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement : The task is to develop machine translation systems that can accurately translate s named entities in the input sentence to the target language.\n",
        "Here, the source language is English and target language is Arabic.\n",
        "\n",
        "\n",
        "*  Named entities are entities that are referred to by proper names, such as people, organizations, locations, dates, and more.\n",
        "* Named entities are often challenging even for human translators, as sometimes there are cultural or domain-specific references that are not easily translatable."
      ],
      "metadata": {
        "id": "L2r_YAdyIbJD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset:\n",
        "The dataset we are using is from the source, mintaka.\n",
        "For our project we are using training and validation data"
      ],
      "metadata": {
        "id": "vCfKUyvwJrn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Install required libraries"
      ],
      "metadata": {
        "id": "5blq4wKUGRYu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OEe3pPZz3nhJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install transformers datasets sentencepiece evaluate sacrebleu --quiet\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Various imports\n"
      ],
      "metadata": {
        "id": "oL3CbZEIGbZn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data handling\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Model & tokenizer handling\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    MBartForConditionalGeneration,         # Pretrained multilingual translation model\n",
        "    MBart50TokenizerFast,                  # Fast tokenizer for mbart50 model\n",
        "    Seq2SeqTrainer,                        # Trainer class for sequence-to-sequence models\n",
        "    Seq2SeqTrainingArguments,              # Training args specific for seq2seq\n",
        "    DataCollatorForSeq2Seq                 # Dynamically pads sequences during batching\n",
        ")\n",
        "\n",
        "# Metric loading for BLEU\n",
        "import evaluate\n"
      ],
      "metadata": {
        "id": "V-RduRXR3p8Y"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download Data then unzip data"
      ],
      "metadata": {
        "id": "DxevxrLKGpw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Download data'''\n",
        "def download_data_and_prep(url,filename):\n",
        "  import requests\n",
        "\n",
        "  response = requests.get(url)\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "  print(f\"{filename} downloaded successfully.\")\n",
        "  '''Unzip the zip file then delete the zip file'''\n",
        "  import zipfile\n",
        "  import os\n",
        "  extract_folder = filename[:-4]  # You can rename this\n",
        "  os.makedirs(extract_folder, exist_ok=True)\n",
        "\n",
        "  with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "  print(f\"Extracted to: {extract_folder}\")\n",
        "\n",
        "\n",
        "  # Delete the zip file\n",
        "\n",
        "  os.remove(filename)\n",
        "  print(f\"Deleted archive: {filename}\")"
      ],
      "metadata": {
        "id": "9eHAScjV34Zf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Give train and validation data url and file name"
      ],
      "metadata": {
        "id": "h_30qJyYG5eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_url = 'https://sapienzanlp.github.io/ea-mt/assets/files/semeval.train.v2-e0d1c28b78c8dd4969d25eea5d3bc9cc.zip'\n",
        "train_filename = 'train_data.zip'\n",
        "val_url = 'https://sapienzanlp.github.io/ea-mt/assets/files/semeval.validation.v2-889a1492ba6c3791baa8f4224bc8e685.zip'\n",
        "val_filename = 'val_data.zip'"
      ],
      "metadata": {
        "id": "DWhK9t154G2u"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download train and validation data"
      ],
      "metadata": {
        "id": "x7zUWI1lG_2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "download_data_and_prep(train_url,train_filename)\n",
        "download_data_and_prep(val_url,val_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAS7xKql4JwF",
        "outputId": "da1fccaf-c1ff-4a5b-f56b-3df6735e8ac0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.zip downloaded successfully.\n",
            "Extracted to: train_data\n",
            "Deleted archive: train_data.zip\n",
            "val_data.zip downloaded successfully.\n",
            "Extracted to: val_data\n",
            "Deleted archive: val_data.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert json data to pandas dataframe"
      ],
      "metadata": {
        "id": "usA_CqXUHMWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Convert json to dataframe'''\n",
        "def json_to_df(path):\n",
        "  import json\n",
        "  import pandas as pd\n",
        "  jsonl_path = path\n",
        "  with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
        "    data = [json.loads(line) for line in f]\n",
        "\n",
        "  # Convert to DataFrame for inspection\n",
        "  df = pd.DataFrame(data)\n",
        "  return df"
      ],
      "metadata": {
        "id": "jEWNV2TA4RDq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Store result in train_df and val_df"
      ],
      "metadata": {
        "id": "ePlAuWT2HS6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Json to df for both train and test\n",
        "train_df = json_to_df(\"train_data/semeval/train/fr/train.jsonl\")\n",
        "val_df = json_to_df(\"val_data/validation/fr_FR.jsonl\")\n"
      ],
      "metadata": {
        "id": "btj71O5a4UEp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Explore Validation dataset"
      ],
      "metadata": {
        "id": "ONOuaGvoHfKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_df['target'] = val_df['targets']\n",
        "val_df.drop('targets',axis=1, inplace= True)\n",
        "val_df['target']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "6sBFToSV4qe8",
        "outputId": "c04d41fb-eabe-442d-81db-1cf5b7bae5f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      [{'translation': 'Quelle est la portée de la N...\n",
              "1      [{'translation': 'Comment la Nomenclature stat...\n",
              "2      [{'translation': 'Pourquoi la Nomenclature sta...\n",
              "3      [{'translation': 'Comment fonctionne l'évoluti...\n",
              "4      [{'translation': 'Qu'est-ce que l'évolution de...\n",
              "                             ...                        \n",
              "719    [{'translation': 'Quel type d'endroit est la m...\n",
              "720    [{'translation': ': Pouvez-vous fournir une br...\n",
              "721    [{'translation': 'Qui est l'auteur du Concerto...\n",
              "722    [{'translation': 'Comment décririe-vous le gen...\n",
              "723    [{'translation': 'Le Concerto pour piano de Sc...\n",
              "Name: target, Length: 724, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[{'translation': 'Quelle est la portée de la N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[{'translation': 'Comment la Nomenclature stat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[{'translation': 'Pourquoi la Nomenclature sta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[{'translation': 'Comment fonctionne l'évoluti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[{'translation': 'Qu'est-ce que l'évolution de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>[{'translation': 'Quel type d'endroit est la m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>720</th>\n",
              "      <td>[{'translation': ': Pouvez-vous fournir une br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>721</th>\n",
              "      <td>[{'translation': 'Qui est l'auteur du Concerto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722</th>\n",
              "      <td>[{'translation': 'Comment décririe-vous le gen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>723</th>\n",
              "      <td>[{'translation': 'Le Concerto pour piano de Sc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>724 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_df[\"target\"][0]))\n",
        "print(train_df[\"target\"][0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmWbIgUB6ZSM",
        "outputId": "bd036a20-76e3-4c51-be5c-f43c4a626c4d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "Quelle est la septième plus haute montagne d’Amérique du Nord ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Since validation set has multiple targets for multiple entities, flaten the target columnn"
      ],
      "metadata": {
        "id": "9eG7GczjHkFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the model to use (mBART supports 50+ languages)\n",
        "Load tokenizer and model from Hugging Face\n",
        "Set the tokenizer's source and target language for encoding input text."
      ],
      "metadata": {
        "id": "aj0U1b0OH3Y9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For train_df: Assume target is a single string already\n",
        "#flat_train_df = train_df.rename(columns={\"source\": \"input\", \"target\": \"target\"})\n",
        "# Wrap Train in entity tags using spacy\n",
        "import spacy\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to wrap detected entities with <entity> tags\n",
        "def tag_entities_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    for ent in reversed(doc.ents):  # Reverse to avoid offset issues\n",
        "        text = text[:ent.start_char] + f\"<entity>{ent.text}</entity>\" + text[ent.end_char:]\n",
        "    return text\n",
        "\n",
        "# Apply to training data\n",
        "train_df[\"input\"] = train_df[\"source\"].apply(tag_entities_spacy)\n",
        "\n",
        "# If train_df[\"target\"] is already clean, keep it\n",
        "train_df[\"target\"] = train_df[\"target\"]  # Or rename as needed\n",
        "\n",
        "\n",
        "# For val_df: Flatten list of translations (target) per source\n",
        "def flatten_val_df(df):\n",
        "    flat_data = []\n",
        "    for _, row in df.iterrows():\n",
        "        #for tgt in row[\"target\"]:  # Each entry is a dict with 'mention' and 'translation'\n",
        "        tgt = row[\"target\"][0] # Take only the first translation\n",
        "        # Use XML-style tags for the entity\n",
        "        tagged_input = row[\"source\"].replace(tgt[\"mention\"], f\"<entity>{tgt['mention']}</entity>\")\n",
        "        flat_data.append({\n",
        "            \"input\": tagged_input,\n",
        "            \"target\": tgt[\"translation\"]\n",
        "        })\n",
        "    return pd.DataFrame(flat_data)\n",
        "\n",
        "flat_val_df = flatten_val_df(val_df)\n"
      ],
      "metadata": {
        "id": "JPgZEP6D4XH-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model to use (mBART supports 50+ languages)\n",
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "# Load tokenizer and model from Hugging Face\n",
        "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)\n",
        "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Define source and target languages.\n",
        "# These should be ISO language codes supported by mBART50.\n",
        "SRC_LANG = \"en_XX\"\n",
        "TGT_LANG = \"fr_FR\"  # Change this to the appropriate target language\n",
        "\n",
        "# Set the tokenizer's source language for encoding input text.\n",
        "tokenizer.src_lang = SRC_LANG\n",
        "tokenizer.tgt_lang = TGT_LANG\n"
      ],
      "metadata": {
        "id": "98-W_0S74kMc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to tokenize each example"
      ],
      "metadata": {
        "id": "QV8TWDL0IFy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to tokenize each example\n",
        "def tokenize_fn(example):\n",
        "    tokenizer.src_lang = \"en_XX\"\n",
        "    model_inputs = tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(example[\"target\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]  # Add labels for training\n",
        "    return model_inputs\n",
        "\n",
        "# Convert pandas to Hugging Face dataset and tokenize\n",
        "train_dataset = Dataset.from_pandas(train_df).map(tokenize_fn)\n",
        "val_dataset = Dataset.from_pandas(flat_val_df).map(tokenize_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137,
          "referenced_widgets": [
            "0005fbf2a87847199378408b09212f84",
            "74aca8dabce041e8a0583200aaff3686",
            "c50e5f28bf4748a1ab4a2746b2f0acc6",
            "92098aa911fa41fca3f774a7de67c5ac",
            "b2434f60b020459d8095e044ea2b71de",
            "1f7c78436f784cabb6756e5090348601",
            "2527478b8dca481c99b2af8ab068687e",
            "908cc113e54c46a8bc2afa33131d72c9",
            "46521500ad6240e8bd1930be4174161a",
            "79da89d71faf40909100f25e39189755",
            "0f82fdbd01d94d7491c4dfa9eef2fed9",
            "a30ea0ddc6bc48bbae6409a5addef14c",
            "d6f7a2d12c114413901d6ddac26ff2be",
            "527162e9b6ee439ca430c5ea67c5515a",
            "9213f10e98004c358d82593202e1321f",
            "afd147215d8b44eba95138a12189b064",
            "070a91728647468a82402f64e8ba3a44",
            "12aa1ada85de4aa68943d074f7c828a5",
            "12f7347b44f4443086bc9e0a9c1e68a3",
            "13f90c06d3b84a5baebf9ebbcede294f",
            "58a9c9ad56f942e4b001f085bd9b7184",
            "73901dd33aab4fdfb00683b2f16e68a8"
          ]
        },
        "id": "S0bf3NFt8aOi",
        "outputId": "cd88c97b-35fa-47b6-dbf3-de763c35b00b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5531 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0005fbf2a87847199378408b09212f84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3950: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/724 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a30ea0ddc6bc48bbae6409a5addef14c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from evaluate import load\n",
        "\n",
        "# Step 1: Load the BLEU metric from Hugging Face evaluate library\n",
        "bleu = load(\"sacrebleu\")\n",
        "\n",
        "# Step 2: Define a compute_metrics function to pass into Seq2SeqTrainer\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred  # Unpack predictions and labels from evaluation output\n",
        "\n",
        "    # Step 3: Decode the predicted token IDs to text\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    # Step 4: Decode label token IDs to text (labels may include padding or -100)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Step 5: BLEU expects references as list of lists. So wrap each label string in a list.\n",
        "    decoded_labels = [[label] for label in decoded_labels]\n",
        "\n",
        "    # Step 6: Compute BLEU score using sacrebleu\n",
        "    return bleu.compute(predictions=decoded_preds, references=decoded_labels)\n"
      ],
      "metadata": {
        "id": "TJ96FBC2-der"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training configuration\n",
        "'''training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./ea_mt_model\",              # Where to save model\n",
        "    per_device_train_batch_size=4,           # Adjust based on RAM\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=6,                      # Total training epochs\n",
        "    learning_rate=5e-5,\n",
        "    logging_dir=\"./logs\",                    # For TensorBoard\n",
        "    save_strategy=\"epoch\",                   # Save after each epoch\n",
        "    eval_strategy=\"epoch\",            # Evaluate on val each epoch\n",
        "    predict_with_generate=True,              # Required for translation\n",
        "    fp16=torch.cuda.is_available(),          # Use FP16 if GPU available\n",
        "    report_to=\"none\",                         # Disable wandb logging\n",
        "\n",
        ")'''\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import Seq2SeqTrainingArguments\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./ea_mt_model\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=10,                          # Use more epochs; early stopping will prevent overfitting\n",
        "    learning_rate=1e-5,\n",
        "    logging_dir=\"./logs\",\n",
        "    eval_strategy=\"epoch\",                 # BLEU evaluated each epoch\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    predict_with_generate=True,\n",
        "    load_best_model_at_end=True,                 # Restore best model using BLEU\n",
        "    metric_for_best_model=\"eval_score\",           # Use BLEU to determine best model\n",
        "    greater_is_better=True,                      # Higher BLEU is better\n",
        "    report_to=\"none\",                            # Disable wandb\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    generation_max_length=128,\n",
        "    generation_num_beams=4,\n",
        "\n",
        ")\n",
        "\n",
        "model.config.forced_bos_token_id = tokenizer.lang_code_to_id[\"fr_XX\"]\n"
      ],
      "metadata": {
        "id": "CzuUkcoA8qwR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainer will handle training loop, eval, saving, etc.\n",
        "'''trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model)\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()'''\n",
        "from transformers import Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer, model),\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  #  Stop if BLEU doesn't improve for 2 epochs\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "_JuY_aU09Mhc",
        "outputId": "76523a52-17a8-48c2-9a09-b34fbc8e1add"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1932093851.py:15: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4149' max='13830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 4149/13830 57:19 < 2:13:49, 1.21 it/s, Epoch 3/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Score</th>\n",
              "      <th>Counts</th>\n",
              "      <th>Totals</th>\n",
              "      <th>Precisions</th>\n",
              "      <th>Bp</th>\n",
              "      <th>Sys Len</th>\n",
              "      <th>Ref Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.099400</td>\n",
              "      <td>0.251144</td>\n",
              "      <td>37.006808</td>\n",
              "      <td>[5357, 3195, 2067, 1319]</td>\n",
              "      <td>[8195, 7471, 6747, 6023]</td>\n",
              "      <td>[65.36912751677852, 42.76535938963994, 30.63583815028902, 21.899385688195252]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8195</td>\n",
              "      <td>8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.058400</td>\n",
              "      <td>0.265434</td>\n",
              "      <td>34.367274</td>\n",
              "      <td>[5285, 3041, 1939, 1238]</td>\n",
              "      <td>[8383, 7659, 6935, 6211]</td>\n",
              "      <td>[63.0442562328522, 39.70492231361796, 27.959625090122568, 19.93237803896313]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8383</td>\n",
              "      <td>8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.040800</td>\n",
              "      <td>0.295097</td>\n",
              "      <td>35.193013</td>\n",
              "      <td>[5292, 3091, 1985, 1239]</td>\n",
              "      <td>[8288, 7564, 6840, 6116]</td>\n",
              "      <td>[63.851351351351354, 40.86462189317821, 29.02046783625731, 20.25833878351864]</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8288</td>\n",
              "      <td>8125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:1737: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3854: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5, 'forced_bos_token_id': 250008}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n",
            "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4149, training_loss=0.2708240455246799, metrics={'train_runtime': 3441.1162, 'train_samples_per_second': 16.073, 'train_steps_per_second': 4.019, 'total_flos': 4494898029920256.0, 'train_loss': 0.2708240455246799, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train size:\", len(train_df))\n",
        "print(\"Val size:\", len(flat_val_df))\n",
        "print(\"\\nSample train:\")\n",
        "print(train_df.sample(3))\n",
        "\n",
        "print(\"\\nSample val:\")\n",
        "print(flat_val_df.sample(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGDj36C_TPy9",
        "outputId": "8d2ec879-ac3a-4704-fe2e-d2061f84c998"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 5531\n",
            "Val size: 724\n",
            "\n",
            "Sample train:\n",
            "            id source_locale target_locale  \\\n",
            "2391  91ebb809            en            fr   \n",
            "3133  7983ef63            en            fr   \n",
            "1157  f6523b5b            en            fr   \n",
            "\n",
            "                                                 source  \\\n",
            "2391              How many husbands did Cleopatra have?   \n",
            "3133  How many times did the U.S. soccer team play i...   \n",
            "1157    Is the Nile River longer than the Amazon River?   \n",
            "\n",
            "                                                 target entities     from  \\\n",
            "2391         Combien de maris Cléopâtre avait-elle eu ?   [Q635]  mintaka   \n",
            "3133  Combien de fois l’équipe des États-Unis de foo...    [Q30]  mintaka   \n",
            "1157            Le Nil est-il plus long que l’Amazone ?  [Q3392]  mintaka   \n",
            "\n",
            "                                                  input  \n",
            "2391  How many husbands did <entity>Cleopatra</entit...  \n",
            "3133  How many times did the <entity>U.S.</entity> s...  \n",
            "1157  Is the <entity>Nile River</entity> longer than...  \n",
            "\n",
            "Sample val:\n",
            "                                                 input  \\\n",
            "650  How many seasons of Diary of a Future Presiden...   \n",
            "204  Who were the participants in the Battle of the...   \n",
            "458  Which country is Mikhail Mishustin the Prime M...   \n",
            "\n",
            "                                                target  \n",
            "650  Combien de saisons de Journal d'une future pré...  \n",
            "204  Qui étaient les participants à la Bataille du ...  \n",
            "458  De quel pays Mikhaïl Michoustine est-il le Pre...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions on validation set\n",
        "results = trainer.predict(val_dataset)\n",
        "\n",
        "# Decode predictions and labels\n",
        "decoded_preds = tokenizer.batch_decode(results.predictions, skip_special_tokens=True)\n",
        "decoded_labels = tokenizer.batch_decode(results.label_ids, skip_special_tokens=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "D0QOhDTu9P4R",
        "outputId": "44ff5575-02d0-4090-e24e-cd45e29c0104"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use sacreBLEU to evaluate translation performance\n",
        "bleu = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "# Wrap references in a list of one ref per prediction\n",
        "refs = [[ref] for ref in decoded_labels]\n",
        "\n",
        "# Compute BLEU score\n",
        "bleu_result = bleu.compute(predictions=decoded_preds, references=refs)\n",
        "print(\"BLEU Score:\", bleu_result[\"score\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bRrU_qvKwhP",
        "outputId": "78aca5be-c043-4e0b-cb93-0d0f740f1942"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 37.00680812347288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work with Base Model to compare with finetuned model"
      ],
      "metadata": {
        "id": "1Z8KJmV1NFZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model to use (mBART supports 50+ languages)\n",
        "base_model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "\n",
        "# Load tokenizer and model from Hugging Face\n",
        "base_tokenizer = MBart50TokenizerFast.from_pretrained(base_model_name)\n",
        "base_model = MBartForConditionalGeneration.from_pretrained(base_model_name)\n",
        "\n",
        "# Define source and target languages.\n",
        "# These should be ISO language codes supported by mBART50.\n",
        "SRC_LANG = \"en_XX\"\n",
        "TGT_LANG = \"fr_XX\"  # Change this to the appropriate target language\n",
        "\n",
        "# Set the tokenizer's source language for encoding input text.\n",
        "base_tokenizer.src_lang = SRC_LANG\n",
        "base_tokenizer.tgt_lang = TGT_LANG\n"
      ],
      "metadata": {
        "id": "s9TU5Cb-M5Cr"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WU-djqHSSxtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "from evaluate import load\n",
        "\n",
        "# Step 1: Load base (untrained) mBART model\n",
        "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "base_model.eval()\n",
        "\n",
        "# Step 2: Generate translations using base model\n",
        "base_predictions = []\n",
        "\n",
        "for example in val_dataset:\n",
        "    # Tokenize input and move to device\n",
        "    inputs = tokenizer(\n",
        "        example[\"input\"],\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    ).to(base_model.device)\n",
        "\n",
        "    # Generate translation (French target)\n",
        "    with torch.no_grad():\n",
        "        output = base_model.generate(\n",
        "            **inputs,\n",
        "            forced_bos_token_id=tokenizer.lang_code_to_id[\"fr_XX\"]\n",
        "        )\n",
        "    decoded = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    base_predictions.append(decoded)\n"
      ],
      "metadata": {
        "id": "Tq9oEJHFPjVw"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build references: list of [target] for each input\n",
        "\n",
        "references = [[t] for t in flat_val_df[\"target\"]]\n",
        "# Evaluate BLEU\n",
        "bleu = load(\"sacrebleu\")\n",
        "bleu_base = bleu.compute(predictions=base_predictions, references=references)\n",
        "\n",
        "print(\"BLEU score (Base model):\", bleu_base[\"score\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydTIDqq_TqPm",
        "outputId": "f3a7459d-9efd-4178-d0ce-a660d305194b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score (Base model): 39.492900673834455\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UftO5C0r6zLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}